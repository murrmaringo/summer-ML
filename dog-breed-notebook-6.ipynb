{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7327,"databundleVersionId":861871,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"gpuType":"T4","provenance":[]},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport zipfile\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import datasets, transforms, models\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom skimage import io, transform\nimport torch.utils.data as data_utils\nimport torchvision.models as models\nfrom tabulate import tabulate\nfrom tqdm.notebook import tqdm\nfrom torch.optim.lr_scheduler import StepLR\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Subset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport timm\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"m-I5OZddbwJW","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.084319Z","iopub.execute_input":"2025-07-23T13:54:33.084605Z","iopub.status.idle":"2025-07-23T13:54:33.091768Z","shell.execute_reply.started":"2025-07-23T13:54:33.084575Z","shell.execute_reply":"2025-07-23T13:54:33.091027Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"''' from google.colab import files\nfiles.upload() '''","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"SjycCjp4bwJY","outputId":"88b61b99-3ed8-4281-c1f6-6da483f76fe3","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.093502Z","iopub.execute_input":"2025-07-23T13:54:33.093781Z","iopub.status.idle":"2025-07-23T13:54:33.109881Z","shell.execute_reply.started":"2025-07-23T13:54:33.093764Z","shell.execute_reply":"2025-07-23T13:54:33.109205Z"}},"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"' from google.colab import files\\nfiles.upload() '"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"'''os.makedirs('/root/.kaggle', exist_ok=True)\n!cp kaggle.json /root/.kaggle/\n!chmod 600 /root/.kaggle/kaggle.json\n!pip install -q kaggle\n\n!kaggle competitions download -c dog-breed-identification\nwith zipfile.ZipFile(\"dog-breed-identification.zip\", 'r') as zip_ref:\n     zip_ref.extractall(\"dog-breed-identification\")'''","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUNVs724bwJY","outputId":"3a00b41c-ad13-435d-cd2f-7a4df33e7f4b","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.110932Z","iopub.execute_input":"2025-07-23T13:54:33.111134Z","iopub.status.idle":"2025-07-23T13:54:33.128186Z","shell.execute_reply.started":"2025-07-23T13:54:33.111119Z","shell.execute_reply":"2025-07-23T13:54:33.127663Z"}},"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"'os.makedirs(\\'/root/.kaggle\\', exist_ok=True)\\n!cp kaggle.json /root/.kaggle/\\n!chmod 600 /root/.kaggle/kaggle.json\\n!pip install -q kaggle\\n\\n!kaggle competitions download -c dog-breed-identification\\nwith zipfile.ZipFile(\"dog-breed-identification.zip\", \\'r\\') as zip_ref:\\n     zip_ref.extractall(\"dog-breed-identification\")'"},"metadata":{}}],"execution_count":108},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/dog-breed-identification'\nlabels = pd.read_csv(f'{DATA_PATH}/labels.csv')\nLE = LabelEncoder()\nlabels['breed_encoded'] = LE.fit_transform(labels['breed'])\n\n# command option c\n\n# Add numerical labels\n\ntrain_df, valid_df = train_test_split(\n    labels,\n    train_size=0.8,\n    shuffle=True,\n    stratify=labels['breed'],\n    random_state=42\n)","metadata":{"id":"GAxLpiHdbwJY","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.128781Z","iopub.execute_input":"2025-07-23T13:54:33.129383Z","iopub.status.idle":"2025-07-23T13:54:33.216028Z","shell.execute_reply.started":"2025-07-23T13:54:33.129366Z","shell.execute_reply":"2025-07-23T13:54:33.215503Z"}},"outputs":[],"execution_count":109},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"id":"PW6Jsi39bwJZ","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.217641Z","iopub.execute_input":"2025-07-23T13:54:33.217848Z","iopub.status.idle":"2025-07-23T13:54:33.222756Z","shell.execute_reply.started":"2025-07-23T13:54:33.217834Z","shell.execute_reply":"2025-07-23T13:54:33.222096Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"class DogBreedDataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.labels_df = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels_df)\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0] + '.jpg')\n        image = Image.open(img_name).convert('RGB')\n        label = self.labels_df.iloc[idx, -1]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\ntrain_dataset = DogBreedDataset(\n    dataframe=train_df,\n    root_dir='/kaggle/input/dog-breed-identification/train',\n    transform=train_transform\n)\n\nvalid_dataset = DogBreedDataset(\n    dataframe=valid_df,\n    root_dir='/kaggle/input/dog-breed-identification/train',\n    transform=val_transform\n)\n\nbatch_size = 64\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4\n)\n\nvalid_loader = DataLoader(\n    valid_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=4\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2z2L9u_SbwJZ","outputId":"a51d5493-212b-4639-91ce-a1e8f9e029fd","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.223565Z","iopub.execute_input":"2025-07-23T13:54:33.223947Z","iopub.status.idle":"2025-07-23T13:54:33.241704Z","shell.execute_reply.started":"2025-07-23T13:54:33.223923Z","shell.execute_reply":"2025-07-23T13:54:33.241156Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"n_classes = 120\nbatch_size = 64\nepochs = 20\nlr = 3e-4\ngamma = 0.7\nseed = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.242477Z","iopub.execute_input":"2025-07-23T13:54:33.242699Z","iopub.status.idle":"2025-07-23T13:54:33.263868Z","shell.execute_reply.started":"2025-07-23T13:54:33.242684Z","shell.execute_reply":"2025-07-23T13:54:33.263241Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"'''efficient_transformer = Linformer(\n    dim=128,\n    seq_len=49+1,  # 7x7 patches + 1 cls-token\n    depth=12,\n    heads=8,\n    k=64\n)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.264484Z","iopub.execute_input":"2025-07-23T13:54:33.264687Z","iopub.status.idle":"2025-07-23T13:54:33.285679Z","shell.execute_reply.started":"2025-07-23T13:54:33.264672Z","shell.execute_reply":"2025-07-23T13:54:33.285123Z"}},"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"'efficient_transformer = Linformer(\\n    dim=128,\\n    seq_len=49+1,  # 7x7 patches + 1 cls-token\\n    depth=12,\\n    heads=8,\\n    k=64\\n)'"},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"# List all available models\navailable_models = timm.list_models()\nif \"vit_small_patch16_224\" in available_models:\n    print(\"yes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.286365Z","iopub.execute_input":"2025-07-23T13:54:33.286970Z","iopub.status.idle":"2025-07-23T13:54:33.305367Z","shell.execute_reply.started":"2025-07-23T13:54:33.286954Z","shell.execute_reply":"2025-07-23T13:54:33.304844Z"}},"outputs":[{"name":"stdout","text":"yes\n","output_type":"stream"}],"execution_count":114},{"cell_type":"code","source":"model = timm.create_model('resnet50.a1_in1k', pretrained=True, num_classes=n_classes).to(device)\nmodel = model.eval()\n\n# get model specific transforms (normalization, resize)\ndata_config = timm.data.resolve_model_data_config(model)\ntransforms = timm.data.create_transform(**data_config, is_training=False)","metadata":{"id":"HGFYHcfJbwJZ","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.305967Z","iopub.execute_input":"2025-07-23T13:54:33.306669Z","iopub.status.idle":"2025-07-23T13:54:33.838867Z","shell.execute_reply.started":"2025-07-23T13:54:33.306645Z","shell.execute_reply":"2025-07-23T13:54:33.838263Z"}},"outputs":[],"execution_count":115},{"cell_type":"code","source":"# loss function\ncriterion = nn.CrossEntropyLoss()\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr)\n# scheduler\nscheduler = StepLR(optimizer, step_size=1, gamma=gamma)","metadata":{"id":"LqBAwAt3bwJZ","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.840848Z","iopub.execute_input":"2025-07-23T13:54:33.841060Z","iopub.status.idle":"2025-07-23T13:54:33.846727Z","shell.execute_reply.started":"2025-07-23T13:54:33.841042Z","shell.execute_reply":"2025-07-23T13:54:33.846270Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install ipywidgets==8.1.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:33.847511Z","iopub.execute_input":"2025-07-23T13:54:33.847730Z","iopub.status.idle":"2025-07-23T13:54:38.115666Z","shell.execute_reply.started":"2025-07-23T13:54:33.847707Z","shell.execute_reply":"2025-07-23T13:54:38.114928Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\nRequirement already satisfied: ipywidgets==8.1.5 in /usr/local/lib/python3.11/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.5) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.5) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.5) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.5) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.5) (3.0.15)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (3.0.51)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (4.9.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.1.5) (0.2.13)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.5) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.5) (0.7.0)\n","output_type":"stream"}],"execution_count":117},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    epoch_loss = 0\n    epoch_accuracy = 0\n\n    for data, label in tqdm(train_loader):\n        data = data.to(device)\n        label = label.to(device)\n\n        # Forward pass\n        output = model(data)\n        loss = criterion(output, label)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()  # Zero the gradients\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update weights\n\n        # Calculate accuracy\n        acc = (output.argmax(dim=1) == label).float().mean()\n        epoch_accuracy += acc.item() / len(train_loader)\n        epoch_loss += loss.item() / len(train_loader)\n\n    # Step the scheduler\n    scheduler.step()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRWMOF7-bwJa","outputId":"5d123d05-4aeb-4976-e2aa-f8b8e4e9abcc","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:54:38.116771Z","iopub.execute_input":"2025-07-23T13:54:38.117076Z","iopub.status.idle":"2025-07-23T14:27:32.504896Z","shell.execute_reply.started":"2025-07-23T13:54:38.117044Z","shell.execute_reply":"2025-07-23T14:27:32.504073Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 128/128 [01:35<00:00,  1.35it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.30it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.30it/s]\n100%|██████████| 128/128 [01:39<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:39<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:39<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.30it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.30it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.30it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:39<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n100%|██████████| 128/128 [01:38<00:00,  1.29it/s]\n","output_type":"stream"}],"execution_count":118},{"cell_type":"code","source":"'''from sklearn.model_selection import ParameterGrid\n\n\nparam_grid = {\n    'lr': [1e-5, 3e-5, 1e-4],\n    'weight_decay': [0.0, 0.01, 0.001],\n    'batch_size': [32, 64]\n}\n\nbest_score = 0\nbest_params = {}\n\nsubset_indices = torch.randperm(len(train_dataset))[:1000]\nsubset_dataset = torch.utils.data.Subset(train_dataset, subset_indices)\n\nfor params in ParameterGrid(param_grid):\n    \n    model = timm.create_model(\n        'resnet50.a1_in1k',\n        pretrained=True,\n        num_classes=len(LE.classes_),\n    ).to(device)\n    \n    subset_loader = DataLoader(\n        subset_dataset,\n        batch_size=params['batch_size'],\n        shuffle=True\n    )\n    \n    optimizer = optim.AdamW(\n        model.parameters(),\n        lr=params['lr'],\n        weight_decay=params['weight_decay']\n    )\n    criterion = nn.CrossEntropyLoss()\n    \n    model.train()\n    for epoch in range(3):\n        epoch_loss = 0\n        epoch_accuracy = 0\n        \n        for data, label in subset_loader:\n            data = data.to(device)\n            label = label.to(device)\n            \n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, label)\n            loss.backward()\n            optimizer.step()\n            \n            acc = (output.argmax(dim=1) == label).float().mean()\n            epoch_accuracy += acc.item() / len(subset_loader)\n            epoch_loss += loss.item() / len(subset_loader)\n        \n        print(f\"Epoch {epoch+1} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n    \n    model.eval()\n    val_accuracy = 0\n    val_loader = DataLoader(valid_dataset, batch_size=64)\n    \n    with torch.no_grad():\n        for data, label in val_loader:\n            data = data.to(device)\n            label = label.to(device)\n            \n            output = model(data)\n            val_accuracy += (output.argmax(dim=1) == label).float().mean().item() / len(val_loader)\n    \n    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n    \n    if val_accuracy > best_score:\n        best_score = val_accuracy\n        best_params = params\n\nprint(\"\\nBest parameters:\", best_params)\nprint(\"Best validation accuracy:\", best_score)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T14:27:32.506341Z","iopub.execute_input":"2025-07-23T14:27:32.506636Z","iopub.status.idle":"2025-07-23T14:27:32.513689Z","shell.execute_reply.started":"2025-07-23T14:27:32.506607Z","shell.execute_reply":"2025-07-23T14:27:32.512993Z"}},"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"'from sklearn.model_selection import ParameterGrid\\n\\n\\nparam_grid = {\\n    \\'lr\\': [1e-5, 3e-5, 1e-4],\\n    \\'weight_decay\\': [0.0, 0.01, 0.001],\\n    \\'batch_size\\': [32, 64]\\n}\\n\\nbest_score = 0\\nbest_params = {}\\n\\nsubset_indices = torch.randperm(len(train_dataset))[:1000]\\nsubset_dataset = torch.utils.data.Subset(train_dataset, subset_indices)\\n\\nfor params in ParameterGrid(param_grid):\\n    \\n    model = timm.create_model(\\n        \\'resnet50.a1_in1k\\',\\n        pretrained=True,\\n        num_classes=len(LE.classes_),\\n    ).to(device)\\n    \\n    subset_loader = DataLoader(\\n        subset_dataset,\\n        batch_size=params[\\'batch_size\\'],\\n        shuffle=True\\n    )\\n    \\n    optimizer = optim.AdamW(\\n        model.parameters(),\\n        lr=params[\\'lr\\'],\\n        weight_decay=params[\\'weight_decay\\']\\n    )\\n    criterion = nn.CrossEntropyLoss()\\n    \\n    model.train()\\n    for epoch in range(3):\\n        epoch_loss = 0\\n        epoch_accuracy = 0\\n        \\n        for data, label in subset_loader:\\n            data = data.to(device)\\n            label = label.to(device)\\n            \\n            optimizer.zero_grad()\\n            output = model(data)\\n            loss = criterion(output, label)\\n            loss.backward()\\n            optimizer.step()\\n            \\n            acc = (output.argmax(dim=1) == label).float().mean()\\n            epoch_accuracy += acc.item() / len(subset_loader)\\n            epoch_loss += loss.item() / len(subset_loader)\\n        \\n        print(f\"Epoch {epoch+1} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\\n    \\n    model.eval()\\n    val_accuracy = 0\\n    val_loader = DataLoader(valid_dataset, batch_size=64)\\n    \\n    with torch.no_grad():\\n        for data, label in val_loader:\\n            data = data.to(device)\\n            label = label.to(device)\\n            \\n            output = model(data)\\n            val_accuracy += (output.argmax(dim=1) == label).float().mean().item() / len(val_loader)\\n    \\n    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\\n    \\n    if val_accuracy > best_score:\\n        best_score = val_accuracy\\n        best_params = params\\n\\nprint(\"\\nBest parameters:\", best_params)\\nprint(\"Best validation accuracy:\", best_score)'"},"metadata":{}}],"execution_count":119},{"cell_type":"code","source":"'''for epoch in range(epochs):\n    model.train()\n    epoch_loss = 0\n    epoch_accuracy = 0\n\n    for data, label in tqdm(train_loader):\n        data = data.to(device)\n        label = label.to(device)\n\n        # Forward pass\n        output = model(data)\n        loss = criterion(output, label)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()  # Zero the gradients\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update weights\n\n        # Calculate accuracy\n        acc = (output.argmax(dim=1) == label).float().mean()\n        epoch_accuracy += acc.item() / len(train_loader)\n        epoch_loss += loss.item() / len(train_loader)\n\n    # Step the scheduler\n    scheduler.step()'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T14:27:32.514443Z","iopub.execute_input":"2025-07-23T14:27:32.514674Z","iopub.status.idle":"2025-07-23T14:27:32.534480Z","shell.execute_reply.started":"2025-07-23T14:27:32.514650Z","shell.execute_reply":"2025-07-23T14:27:32.533825Z"}},"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"'for epoch in range(epochs):\\n    model.train()\\n    epoch_loss = 0\\n    epoch_accuracy = 0\\n\\n    for data, label in tqdm(train_loader):\\n        data = data.to(device)\\n        label = label.to(device)\\n\\n        # Forward pass\\n        output = model(data)\\n        loss = criterion(output, label)\\n\\n        # Backward pass and optimization\\n        optimizer.zero_grad()  # Zero the gradients\\n        loss.backward()  # Backpropagation\\n        optimizer.step()  # Update weights\\n\\n        # Calculate accuracy\\n        acc = (output.argmax(dim=1) == label).float().mean()\\n        epoch_accuracy += acc.item() / len(train_loader)\\n        epoch_loss += loss.item() / len(train_loader)\\n\\n    # Step the scheduler\\n    scheduler.step()'"},"metadata":{}}],"execution_count":120},{"cell_type":"code","source":"import torch.nn.functional as F\nfrom PIL import Image\nfrom tqdm import tqdm\n\ndef create_submission(model, test_dir, transform, device, breed_names, sample_submission_path):\n    # Read the sample submission file to get the correct format\n    sample_submission = pd.read_csv(sample_submission_path)\n    \n    test_files = os.listdir(test_dir)\n    model.eval()  # Set the model to evaluation mode\n\n    # Initialize predictions dictionary with zeros\n    preds_dict = {img_id: np.zeros(len(breed_names)) for img_id in sample_submission['id']}\n\n    for file in tqdm(test_files, desc=\"Processing Test Images\"):\n        img_id = file.split('.')[0]\n        if img_id not in preds_dict:\n            continue  # Skip files not in the sample submission\n\n        img_path = os.path.join(test_dir, file)\n        image = Image.open(img_path).convert('RGB')\n        image = transform(image).unsqueeze(0).to(device)\n\n        with torch.no_grad():  # Disable gradient calculation\n            output = model(image)\n            probas = F.softmax(output, dim=1).cpu().numpy()[0]\n        \n        preds_dict[img_id] = probas\n\n    # Create the submission DataFrame\n    submission = sample_submission.copy()\n    for i, breed in enumerate(breed_names):\n        if breed in submission.columns:\n            submission[breed] = submission['id'].map(lambda x: preds_dict[x][i])\n\n    return submission\n\n# Correct paths (example paths - adjust according to your actual dataset)\ntest_dir = '/kaggle/input/dog-breed-identification/test'  # Should be test directory, not train\nsample_submission_path = '/kaggle/input/dog-breed-identification/sample_submission.csv'  # Actual sample submission file\n\n# Generate submission file\n# Assuming LE is your LabelEncoder object (should be defined elsewhere in your code)\nbreed_names = LE.classes_  # Make sure LE is properly defined\nsubmission = create_submission(\n    model, \n    test_dir, \n    val_transform, \n    device, \n    breed_names,\n    sample_submission_path\n)\n\n# Save the submission\noutput_dir = '/kaggle/working'\nos.makedirs(output_dir, exist_ok=True)\noutput_path = os.path.join(output_dir, 'submission.csv')\nsubmission.to_csv(output_path, index=False)\n\nprint(\"Submission shape:\", submission.shape)\nprint('Submission file created successfully!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T14:27:32.535251Z","iopub.execute_input":"2025-07-23T14:27:32.535501Z","iopub.status.idle":"2025-07-23T14:29:53.264590Z","shell.execute_reply.started":"2025-07-23T14:27:32.535480Z","shell.execute_reply":"2025-07-23T14:29:53.263847Z"}},"outputs":[{"name":"stderr","text":"Processing Test Images: 100%|██████████| 10357/10357 [02:18<00:00, 74.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Submission shape: (10357, 121)\nSubmission file created successfully!\n","output_type":"stream"}],"execution_count":121},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}